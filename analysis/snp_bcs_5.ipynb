{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "%load_ext rpy2.ipython\n",
    "\n",
    "from cap2.capalyzer.pangea import PangeaFileSource\n",
    "from cap2.capalyzer.pangea.utils import get_pangea_group\n",
    "from cap2.capalyzer.table_builder import CAPTableBuilder\n",
    "\n",
    "from plotnine import *\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from glob import glob\n",
    "from os.path import isfile\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "twins_group = get_pangea_group('Mason Lab', 'NASA Twins', 'dcdanko@gmail.com', )\n",
    "twins_source = PangeaFileSource(twins_group)\n",
    "twins = CAPTableBuilder('twins', twins_source)\n",
    "iss_group = get_pangea_group('Mason Lab', 'NASA ISS', 'dcdanko@gmail.com', )\n",
    "iss_source = PangeaFileSource(iss_group)\n",
    "iss = CAPTableBuilder('iss', iss_source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import networkx as nx\n",
    "from functools import lru_cache\n",
    "\n",
    "class SNPBarcode:\n",
    "\n",
    "    def __init__(self, tbl):\n",
    "        self.tbl = tbl\n",
    "        self.sample_name = tbl['sample_name'].unique()[0]\n",
    "        self.seq = tbl['seq'].unique()[0]\n",
    "        self.snps = set(zip(tbl['coord'], tbl['changed']))\n",
    "        self.min_pos = 1000 * 1000 * 1000\n",
    "        self.max_pos = -1\n",
    "        for pos, _ in self.snps:\n",
    "            if pos < self.min_pos:\n",
    "                self.min_pos = pos\n",
    "            if pos > self.max_pos:\n",
    "                self.max_pos = pos\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.snps)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.sample_name + ';' + self.seq + ';' + ','.join([f'{a}:{b}' for a, b in sorted(list(self.snps))])    \n",
    "    def __hash__(self):\n",
    "        return hash(str(self))\n",
    "\n",
    "\n",
    "class SNPBarcodeSet:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.seq = None\n",
    "        self.snps = set([])\n",
    "        self.barcodes = []\n",
    "        self.min_pos = 1000 * 1000 * 1000\n",
    "        self.max_pos = -1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.snps)\n",
    "\n",
    "    def add_barcode(self, bc):\n",
    "        if self.seq:\n",
    "            assert bc.seq == self.seq\n",
    "        else:\n",
    "            self.seq = bc.seq\n",
    "        self.snps |= bc.snps\n",
    "        if bc.min_pos < self.min_pos:\n",
    "            self.min_pos = bc.min_pos\n",
    "        if bc.max_pos > self.max_pos:\n",
    "            self.max_pos = bc.max_pos\n",
    "        self.barcodes.append(bc)\n",
    "        return self\n",
    "\n",
    "\n",
    "def barcode_barcode_similarity(b1, b2):\n",
    "    if b1.seq != b2.seq:\n",
    "        return 0\n",
    "    if b1.min_pos > b2.max_pos:\n",
    "        return 0\n",
    "    if b1.max_pos < b2.min_pos:\n",
    "        return 0\n",
    "    jaccard = len(b1.snps & b2.snps) / min(len(b1.snps), len(b2.snps))\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "def barcode_barcode_set_similarity(bc, bc_set):\n",
    "    if bc.seq != bc_set.seq:\n",
    "        return 0\n",
    "    if bc.min_pos > bc_set.max_pos:\n",
    "        return 0\n",
    "    if bc.max_pos < bc_set.min_pos:\n",
    "        return 0\n",
    "    jaccard = len(bc.snps & bc_set.snps) / min(len(bc.snps), len(bc_set.snps))\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "def build_barcode_sets(barcodes, sim_thresh=0.5):\n",
    "    \"\"\"Return a list of SNPBarcodeSets that fulfill sevreal reqs.\n",
    "\n",
    "     - all barcodes are in one or more barcode sets\n",
    "     - each barcode in a set has similarity of at least sim_thresh to that set\n",
    "    \"\"\"\n",
    "    barcode_sets = []\n",
    "    for i, bc in enumerate(barcodes):\n",
    "        if i % (25 * 1000) == 0:\n",
    "            print(i, len(barcode_sets))\n",
    "        added_to_bc_set = False\n",
    "        for bc_set in barcode_sets:\n",
    "            s = barcode_barcode_set_similarity(bc, bc_set)\n",
    "            if s < sim_thresh:\n",
    "                continue\n",
    "            added_to_bc_set = True\n",
    "            bc_set.add_barcode(bc)\n",
    "        if not added_to_bc_set:\n",
    "            new_bc_set = SNPBarcodeSet().add_barcode(bc)\n",
    "            barcode_sets.append(new_bc_set)\n",
    "    return barcode_sets\n",
    "\n",
    "\n",
    "def barcode_barcode_similarity_graph(barcodes, external_bcs=[], sim_thresh=0.5):\n",
    "    \"\"\"Return a Graph with edges between similar barcodes.\n",
    "\n",
    "    - Barcodes with no similar barcdoes are not included\n",
    "    - weight of each edge is the similarity\n",
    "    \"\"\"\n",
    "    barcode_sets = build_barcode_sets(barcodes, sim_thresh=sim_thresh)\n",
    "    G = nx.Graph()\n",
    "    for bc_set in barcode_sets:\n",
    "        for bc1 in bc_set.barcodes:\n",
    "            for bc2 in bc_set.barcodes:\n",
    "                if bc1 == bc2:\n",
    "                    break\n",
    "                s = barcode_barcode_similarity(bc1, bc2)\n",
    "                if s >= sim_thresh:\n",
    "                    G.add_edge(bc1, bc2, weight=s)\n",
    "    \n",
    "    comps = list(nx.connected_components(G))\n",
    "    print(f'finished building clusters. attaching externals to {len(comps)} clusters.')\n",
    "    comp_count = {}\n",
    "    for i, bc1 in enumerate(external_bcs):\n",
    "        if i % (50 * 1000) == 0:\n",
    "            print(f'Processed {i} external bcs')\n",
    "        for comp_ind, comp in enumerate(comps):\n",
    "            if comp_count.get(comp_ind, 0) >= 2:\n",
    "                continue\n",
    "            for bc2 in comp:\n",
    "                s = barcode_barcode_similarity(bc1, bc2)\n",
    "                if s >= sim_thresh:\n",
    "                    comp_count[comp_ind] = comp_count.get(comp_ind, 0) + 1\n",
    "                    G.add_edge(bc1, bc2, weight=s)\n",
    "                    break\n",
    "                \n",
    "    return G\n",
    "\n",
    "def parse_snp_clusters(sample_name, filepath):\n",
    "    tbl = pd.read_csv(filepath, compression='gzip', index_col=0)\n",
    "    tbl = tbl.query('weight >= 10')\n",
    "    tbl['sample_name'] = sample_name\n",
    "    barcodes = [bc for bc in tbl.groupby('cluster').apply(SNPBarcode) if len(bc) >= 5]\n",
    "    return barcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_graph(organism):\n",
    "    twins_filepaths = list(twins_source('cap2::experimental::make_snp_clusters', f'snp_clusters__{organism}'))\n",
    "    iss_filepaths = list(iss_source('cap2::experimental::make_snp_clusters', f'snp_clusters__{organism}'))\n",
    "    all_barcodes = []\n",
    "    for sample_name, filepath in twins_filepaths:\n",
    "        try:\n",
    "            all_barcodes += parse_snp_clusters(sample_name, filepath)\n",
    "        except:\n",
    "            pass\n",
    "    iss_barcodes = []\n",
    "    for sample_name, filepath in iss_filepaths:\n",
    "        try:\n",
    "            iss_barcodes += parse_snp_clusters(sample_name, filepath)\n",
    "        except:\n",
    "            pass\n",
    "    print(len(all_barcodes), len(iss_barcodes))\n",
    "\n",
    "    G = barcode_barcode_similarity_graph(all_barcodes, external_bcs=iss_barcodes)\n",
    "    return G\n",
    "\n",
    "\n",
    "def get_component_table(G):\n",
    "    tbl = {}\n",
    "    for i, c in enumerate(nx.connected_components(G)):\n",
    "        if len(c) == 1:\n",
    "            continue\n",
    "        tbl[i] = {}\n",
    "        for bc in c:\n",
    "            tbl[i][bc.sample_name] = 1\n",
    "    tbl = pd.DataFrame.from_dict(tbl, orient='columns')\n",
    "    return tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bifidobacterium_pseudocatenulatum\n"
     ]
    }
   ],
   "source": [
    "strain_list = [\n",
    "    'Bifidobacterium_pseudocatenulatum',\n",
    "    'Fusobacterium_necrophorum',\n",
    "    'Serratia_proteamaculans'\n",
    "    'Brevibacterium_siliguriense',\n",
    "    'Gordonibacter_urolithinfaciens',\n",
    "    'Bacillus_albus',\n",
    "    'Gluconobacter_albidus',\n",
    "    'Geobacillus_stearothermophilus',\n",
    "    'Bifidobacterium_catenulatum',\n",
    "    'Streptococcus_viridans', # 10\n",
    "    'Bacteroides_caccae',\n",
    "    'Vibrio_alginolyticus',\n",
    "    'Staphylococcus_sciuri',\n",
    "    'Pectobacterium_parmentieri',\n",
    "    'Cronobacter_condimenti',\n",
    "    'Campylobacter_lari',\n",
    "    'Atlantibacter_hermannii',\n",
    "    'Bacillus_tequilensis',\n",
    "    'Achromobacter_ruhlandii',\n",
    "    'Serratia_proteamaculans', #20\n",
    "    'Leptotrichia_hongkongensis',\n",
    "    'Exiguobacterium_antarcticum',\n",
    "    'Brenneria_rubrifaciens',\n",
    "    'Staphylococcus_simiae',\n",
    "    'Anoxybacillus_amylolyticus',\n",
    "    'Kosakonia_sacchari',\n",
    "    'Yersinia_canariae',\n",
    "    'Providencia_heimbachae',\n",
    "    'Spirochaeta_perfilievii', # 29\n",
    "][:3]\n",
    "\n",
    "organism_components = {}\n",
    "for organism in strain_list:\n",
    "    print(organism)\n",
    "    G = get_graph(organism)\n",
    "    print('made graph')\n",
    "    tbl = get_component_table(G)\n",
    "    print('made table')\n",
    "    organism_components[organism] = (G, tbl)\n",
    "    \n",
    "organism_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
